{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线性回归的矩阵理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线性回归的优缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线性回归的损失函数\n",
    "使损失函数的值最小的两种算法：\n",
    "1. 最小二乘法，对应API LinearRegression\n",
    "2. 梯度下降，对应API SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235 ,\n",
       "       -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load datasets\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "diabetes.data[0]\n",
    "#diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "         normalize=False)\n",
      "打印出估计得到的参数数组：\n",
      "[  -52.20681786  -294.96059868   523.26395511   311.19201914\n",
      " -1187.66470625   812.42453627   279.62989757   207.36828778\n",
      "   979.84062551    60.31107646]\n",
      "==============================\n",
      "打印出intercept：\n",
      "154.41876096593253\n",
      "==============================\n",
      "3329.3627201306713\n"
     ]
    }
   ],
   "source": [
    "def linearReg(data):\n",
    "    \n",
    "    # split data into traina and test\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size = 0.25)\n",
    "    \n",
    "    # initialize linearRegression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lg = LinearRegression()\n",
    "    lg.fit(x_train, y_train)\n",
    "    print(lg)\n",
    "    print(\"打印出估计得到的参数数组：\")\n",
    "    print(lg.coef_)\n",
    "    print(\"=\" * 30)\n",
    "    print(\"打印出intercept：\")\n",
    "    print(lg.intercept_)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # mean square error\n",
    "    # 计算测试集中预测值和真实值均方差的大小\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(mean_squared_error(lg.predict(x_test), y_test))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    linearReg(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False)\n",
      "打印出估计得到的参数数组：\n",
      "[ 2.2399586  -0.25403273  7.02150706  4.9337737   2.86965303  2.54912641\n",
      " -5.11137055  5.67829862  7.09592256  5.19645307]\n",
      "==============================\n",
      "打印出intercept：\n",
      "[146.54208039]\n",
      "==============================\n",
      "5679.25203113119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cail/anaconda/envs/jupyterlab/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def SGDReg(data):\n",
    "    \n",
    "    # split data into traina and test\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size = 0.25)\n",
    "    \n",
    "    # initialize linearRegression\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    lg = SGDRegressor(alpha=0.0001)\n",
    "    lg.fit(x_train, y_train)\n",
    "    print(lg)\n",
    "    print(\"打印出估计得到的参数数组：\")\n",
    "    print(lg.coef_)\n",
    "    print(\"=\" * 30)\n",
    "    print(\"打印出intercept：\")\n",
    "    print(lg.intercept_)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # mean square error\n",
    "    # 计算测试集中预测值和真实值均方差的大小\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(mean_squared_error(lg.predict(x_test), y_test))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SGDReg(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 保存模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
